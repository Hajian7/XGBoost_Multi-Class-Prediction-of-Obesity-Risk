{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sajjadhajian/xgboost-multi-class-prediction-of-obesity-risk?scriptVersionId=163030129\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"2a69c63c","metadata":{"execution":{"iopub.execute_input":"2024-02-16T03:10:40.625985Z","iopub.status.busy":"2024-02-16T03:10:40.625273Z","iopub.status.idle":"2024-02-16T03:11:24.274581Z","shell.execute_reply":"2024-02-16T03:11:24.273348Z"},"papermill":{"duration":43.657506,"end_time":"2024-02-16T03:11:24.278565","exception":false,"start_time":"2024-02-16T03:10:40.621059","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["submission:           id           NObeyesdad\n","0      20758      Obesity_Type_II\n","1      20759   Overweight_Level_I\n","2      20760     Obesity_Type_III\n","3      20761       Obesity_Type_I\n","4      20762     Obesity_Type_III\n","...      ...                  ...\n","13835  34593  Overweight_Level_II\n","13836  34594   Overweight_Level_I\n","13837  34595  Insufficient_Weight\n","13838  34596        Normal_Weight\n","13839  34597      Obesity_Type_II\n","\n","[13840 rows x 2 columns]\n"]}],"source":["# Import libraries\n","import pandas as pd\n","import numpy as np\n","import re\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","from xgboost import XGBClassifier \n","\n","\n","# Read the data\n","file_path = '/kaggle/input/playground-series-s4e2/train.csv' \n","file_path2 = '/kaggle/input/playground-series-s4e2/test.csv'  \n","\n","df = pd.read_csv(file_path)\n","df2 = pd.read_csv(file_path2)\n","\n","submission_id = df2['id'].reset_index(drop=True)\n","\n","df = df.drop(columns='id')\n","df2 = df2.drop(columns='id')\n","\n","\n","# Optimize datatypes\n","for col in df.columns:\n","    if df[col].dtype == 'object':\n","        df[col] = df[col].astype('category')\n","    \n","for col in df2.columns:\n","    if df2[col].dtype == 'object':\n","        df2[col] = df2[col].astype('category')\n","\n","        \n","# Define the mapping from category to label\n","NObeyesdad_label = {\n","    'Insufficient_Weight': 0,\n","    'Normal_Weight': 1,\n","    'Overweight_Level_I': 2,\n","    'Overweight_Level_II': 3,\n","    'Obesity_Type_I': 4,\n","    'Obesity_Type_II': 5,\n","    'Obesity_Type_III': 6\n","}\n","df['NObeyesdad'] = df['NObeyesdad'].map(NObeyesdad_label).astype('int8')\n","\n","\n","# Define the mapping from category to label\n","family_history_with_overweight_label = {\n","    'yes': 2,\n","    'no': 1\n","}\n","df['family_history_with_overweight'] = df['family_history_with_overweight'].map(family_history_with_overweight_label).astype('int8')\n","df2['family_history_with_overweight'] = df2['family_history_with_overweight'].map(family_history_with_overweight_label).astype('int8')\n","\n","\n","# Define the mapping from category to label\n","FAVC_label = {\n","    'no': 1,\n","    'yes': 2\n","}\n","df['FAVC'] = df['FAVC'].map(FAVC_label).astype('int8')\n","df2['FAVC'] = df2['FAVC'].map(FAVC_label).astype('int8')\n","\n","\n","# Define the mapping from category to label\n","CAEC_label = {\n","    'Sometimes': 2,\n","    'Frequently': 3,\n","    'Always': 4,\n","    'no': 1\n","}\n","df['CAEC'] = df['CAEC'].map(CAEC_label).astype('int8')\n","df2['CAEC'] = df2['CAEC'].map(CAEC_label).astype('int8')\n","\n","\n","# Define the mapping from category to label\n","SMOKE_label = {\n","    'no': 1,\n","    'yes': 2\n","}\n","df['SMOKE'] = df['SMOKE'].map(SMOKE_label).astype('int8')\n","df2['SMOKE'] = df2['SMOKE'].map(SMOKE_label).astype('int8')\n","\n","\n","# Define the mapping from category to label\n","CALC_label = {\n","    'no': 1,\n","    'Sometimes' : 2,\n","    'Frequently': 3,\n","    'Always':4\n","}\n","df['CALC'] = df['CALC'].map(CALC_label).astype('int8')\n","df2['CALC'] = df2['CALC'].map(CALC_label).astype('int8')\n","\n","\n","# Define the mapping from category to label\n","SCC_label = {\n","    'no': 2,\n","    'yes': 1\n","}\n","df['SCC'] = df['SCC'].map(SCC_label).astype('int8')\n","df2['SCC'] = df2['SCC'].map(SCC_label).astype('int8')\n","\n","\n","# Define the mapping from category to label\n","MTRANS_label = {\n","    'Public_Transportation': 3,\n","    'Automobile': 5 ,\n","    'Walking': 1 ,\n","    'Bike': 2 ,\n","    'Motorbike': 4\n","}\n","df['MTRANS'] = df['MTRANS'].map(MTRANS_label).astype('int8')\n","df2['MTRANS'] = df2['MTRANS'].map(MTRANS_label).astype('int8')\n","\n","\n","\n","# One-hot encoding\n","categorical_columns = df.select_dtypes(include='category').columns\n","df_categorical = df[categorical_columns]\n","df_numerical = df.select_dtypes(exclude='category')\n","df_dummies = pd.get_dummies(df_categorical, columns=categorical_columns, drop_first=True, dtype=int, sparse=True)\n","df = pd.concat([df_numerical, df_dummies], axis=1)\n","regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n","df.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in df.columns.values]\n","\n","\n","# One-hot encoding\n","categorical_columns2 = df2.select_dtypes(include='category').columns\n","df2_categorical = df2[categorical_columns2]\n","df2_numerical = df2.select_dtypes(exclude='category')\n","df2_dummies = pd.get_dummies(df2_categorical, columns=categorical_columns2, drop_first=True, dtype=int, sparse=True)\n","df2 = pd.concat([df2_numerical, df2_dummies], axis=1)\n","regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n","df2.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in df2.columns.values]\n","\n","\n","X = df.drop(columns='NObeyesdad')\n","y = df['NObeyesdad']\n","\n","\n","# Modeling \n","\n","model = XGBClassifier(objective='multi:softprob',num_class=len(np.unique(y)), random_state=1, eval_metric='merror')\n","model.fit(X,y)\n","\n","label_to_category = {\n","    0: 'Insufficient_Weight',\n","    1: 'Normal_Weight',\n","    2: 'Overweight_Level_I',\n","    3: 'Overweight_Level_II',\n","    4: 'Obesity_Type_I',\n","    5: 'Obesity_Type_II',\n","    6: 'Obesity_Type_III'\n","}\n","\n","# Improve the predictions\n","mask = (y == 2) | (y == 3)\n","X_23 = X[mask]\n","y_23 = y[mask]\n","y_23 = (y_23 == 3).astype('int')\n","model_23 = XGBClassifier(objective='binary:logistic', random_state=1, eval_metric='error')\n","model_23.fit(X_23, y_23)\n","classes_23 = ['Overweight_Level_I', 'Overweight_Level_II']\n","\n","# y_pred_23 = y_pred\n","# for i in range(len(y_pred_23)):\n","#     if y_pred_23[i] in ['Overweight_Level_I', 'Overweight_Level_II']:\n","#         new_pred_23 = model_23.predict(X_test[i:i+1])[0]\n","#         new_pred_23 = classes_23[new_pred_23]\n","#         y_pred_23[i] = new_pred_23\n","\n","# print(np.unique(y_pred_23))\n","\n","mask = (y == 3) | (y == 4)\n","X_34 = X[mask]\n","y_34 = y[mask]\n","y_34 = (y_34 == 4).astype('int')\n","classes_34 = ['Overweight_Level_II','Obesity_Type_I']\n","model_34 = XGBClassifier(objective='binary:logistic', random_state=1, eval_metric='error')\n","model_34.fit(X_34, y_34)\n","\n","# y_pred_34 = y_pred_23\n","# for i in range(len(y_pred_34)):\n","#     if y_pred_34[i] in ['Obesity_Type_I', 'Overweight_Level_II']:\n","#         new_pred_34 = model_34.predict(X_test[i:i+1])[0]\n","#         new_pred_34 = classes_34[new_pred_34]\n","#         y_pred_34[i] = new_pred_34\n","\n","mask = (y == 1) | (y == 2)\n","X_12 = X[mask]\n","y_12 = y[mask]\n","classes_12 = ['Normal_Weight', 'Overweight_Level_I']\n","y_12 = (y_12 == 2).astype('int')\n","model_12 = XGBClassifier(objective='binary:logistic', random_state=1, eval_metric='error')\n","model_12.fit(X_12, y_12)\n","\n","# y_pred_12 = y_pred_34\n","# for i in range(len(y_pred_12)):\n","#     if y_pred_12[i] in ['Normal_Weight', 'Overweight_Level_I']:\n","#         new_pred_12 = model_12.predict(X_test[i:i+1])[0]\n","#         new_pred_12 = classes_12[new_pred_12]\n","#         y_pred_12[i] = new_pred_12\n","            \n","\n","# Submission\n","# y_pred = pd.Series(model.predict(X_test)).map(label_to_category).astype('str')\n","new_pred = pd.Series(model.predict(df2)).map(label_to_category).astype('str')\n","# new_pred = new_pred.map(label_to_category)\n","for i in range(len(new_pred)):\n","    if new_pred[i] in ['Overweight_Level_I', 'Overweight_Level_II']:\n","        new_pred[i] = classes_23[model_23.predict(df2[i:i+1])[0]]\n","for i in range(len(new_pred)):\n","    if new_pred[i] in ['Obesity_Type_I', 'Overweight_Level_II']:\n","        new_pred[i] = classes_34[model_34.predict(df2[i:i+1])[0]]\n","for i in range(len(new_pred)):\n","    if new_pred[i] in ['Normal_Weight', 'Overweight_Level_I']:\n","        new_pred[i] = classes_12[model_12.predict(df2[i:i+1])[0]]\n","        \n","\n","\n","# Create a new DataFrame with the required columns\n","XGBoost_submission = pd.DataFrame({\n","     'id': submission_id,\n","     'NObeyesdad': new_pred\n"," })\n","\n","print('submission:', XGBoost_submission)\n","\n","# Save the submission as a CSV file\n","XGBoost_submission.to_csv('submission.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7609535,"sourceId":68479,"sourceType":"competition"}],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":47.121205,"end_time":"2024-02-16T03:11:24.900519","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-16T03:10:37.779314","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}